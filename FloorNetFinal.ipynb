{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FloorNetFinal",
      "provenance": [],
      "authorship_tag": "ABX9TyP7el1yHRRKISdQ59ZrWSGo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devShaurya/Summer-Intern/blob/master/FloorNetFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZz3jHEh4Nlf",
        "colab_type": "text"
      },
      "source": [
        "## Clone the floorNet repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWNm6VmF4R88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/art-programmer/FloorNet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW516dPD4VwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd FloorNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUFI7Qf12vR-",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDcjDLji3fRn",
        "colab_type": "text"
      },
      "source": [
        "Use [this](https://drive.google.com/open?id=16lyX_xTiALUzKyst86WJHlhpTDr8XPF_) or [this](https://mega.nz/#F!5yQy0b5T!ykkR4dqwGO9J5EwnKT_GBw) link to download the dataset files. As you will see, the images of floorplans are stored in .tfrecords format. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMcZcul63ui1",
        "colab_type": "text"
      },
      "source": [
        "The readme of FloorNet suggests to read RecordWriterTango.py and some tutorials for understanding the .tfrecords format. But we don't need to read those. Read [this](https://www.tensorflow.org/tutorials/load_data/tfrecord) tutorial to learn more understand about tfrecords format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1mvANln5Yfu",
        "colab_type": "text"
      },
      "source": [
        "If you read that tutorial, or you already know about tfrecords format than you will understand that tfrecords are used to save data in key-value pairs. Hence we need to know the keys for extracting the code out of these tfrecords. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYt5swE95-PU",
        "colab_type": "text"
      },
      "source": [
        "RecordReader.py file is the one which helps in reading the data in FloorNet pipeline so we can use it for extracting data. It also mentions the key-value pairs too"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl6VOtE56WhL",
        "colab_type": "text"
      },
      "source": [
        "After downloading the data, save it under \"data\" folder of FloorNet repo and follow this notebook for extraction of the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vPAw2T36hAY",
        "colab_type": "text"
      },
      "source": [
        "## Extraction of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC2yWqwH67WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Run this cell first before other cells else some of the next cells give weird errors\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99WqZNBs68Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from RecordReader import *\n",
        "from augmentation_tf import *\n",
        "from floorplan_utils import *\n",
        "from utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bM9tjGO75o0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "filenames=['data/Tango_train.tfrecords']\n",
        "\n",
        "augmentation=\"\"\n",
        "\n",
        "batchSize=6\n",
        "\n",
        "readImageFeatures=True\n",
        "\n",
        "converCorners=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hiHVzzh79d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_fn(example, augmentation='', readImageFeatures = True, convertCorners=True, kernelSize=11):\n",
        "    if readImageFeatures:\n",
        "        features = tf.parse_single_example(\n",
        "            example,\n",
        "            # Defaults are not specified since both keys are required.\n",
        "            features={\n",
        "                'image_path': tf.FixedLenFeature([], tf.string),\n",
        "                'points': tf.FixedLenFeature([NUM_POINTS * (NUM_INPUT_CHANNELS - 1)], tf.float32),\n",
        "                'point_indices': tf.FixedLenFeature([NUM_POINTS], tf.int64),\n",
        "                'corner': tf.FixedLenFeature([MAX_NUM_CORNERS * 3], tf.int64),\n",
        "                'num_corners': tf.FixedLenFeature([], tf.int64),\n",
        "                'icon': tf.FixedLenFeature([], tf.string),\n",
        "                'room': tf.FixedLenFeature([], tf.string),\n",
        "                'image': tf.FixedLenFeature(sum([size * size * numChannels for size, numChannels in list(zip(SIZES, NUM_CHANNELS))[1:]]), tf.float32),\n",
        "                'flags': tf.FixedLenFeature([2], tf.int64),\n",
        "            })\n",
        "    else:\n",
        "        features = tf.parse_single_example(\n",
        "            example,\n",
        "            # Defaults are not specified since both keys are required.\n",
        "            features={\n",
        "                'image_path': tf.FixedLenFeature([], tf.string),\n",
        "                'points': tf.FixedLenFeature([NUM_POINTS * (NUM_INPUT_CHANNELS - 1)], tf.float32),\n",
        "                'point_indices': tf.FixedLenFeature([NUM_POINTS], tf.int64),\n",
        "                'corner': tf.FixedLenFeature([MAX_NUM_CORNERS * 3], tf.int64),\n",
        "                'num_corners': tf.FixedLenFeature([], tf.int64),\n",
        "                'icon': tf.FixedLenFeature([], tf.string),\n",
        "                'room': tf.FixedLenFeature([], tf.string),\n",
        "                'flags': tf.FixedLenFeature([2], tf.int64),\n",
        "            })\n",
        "        pass\n",
        "\n",
        "    points = tf.reshape(features['points'], (NUM_POINTS, NUM_INPUT_CHANNELS - 1))\n",
        "    point_indices = tf.cast(features['point_indices'], tf.int32)\n",
        "    #point_indices = features['point_indices']\n",
        "\n",
        "    corners = tf.cast(tf.reshape(features['corner'], [MAX_NUM_CORNERS, 3]), tf.int32)\n",
        "    numCorners = features['num_corners']\n",
        "    corners = corners[:numCorners]\n",
        "    iconSegmentation = tf.reshape(tf.decode_raw(features['icon'], tf.uint8), (HEIGHT, WIDTH, 1))\n",
        "    roomSegmentation = tf.reshape(tf.decode_raw(features['room'], tf.uint8), (HEIGHT, WIDTH, 1))\n",
        "    heatmaps = tf.stack([iconSegmentation, roomSegmentation], axis=0)\n",
        "\n",
        "    if readImageFeatures:\n",
        "        imageFeature = features['image']\n",
        "        imageFeatures = {}\n",
        "        offset = 0\n",
        "#         print(SIZES,NUM_CHANNELS)\n",
        "        new_zip=list(zip(SIZES, NUM_CHANNELS))\n",
        "#         print(type(new_zip))\n",
        "        for index, (size, numChannels) in enumerate(new_zip[1:]):\n",
        "            imageFeatures[index] = tf.reshape(imageFeature[offset:offset + size * size * numChannels], (size, size, numChannels))\n",
        "            offset += size * size * numChannels\n",
        "            continue\n",
        "    else:\n",
        "        imageFeatures = {}\n",
        "        pass\n",
        "\n",
        "    flags = features['flags']\n",
        "    if 'w' in augmentation:\n",
        "        point_indices, corners, heatmaps = tf.cond(tf.logical_or(tf.equal(flags[0], 0), tf.equal(flags[0], 4)), lambda: augmentWarping(point_indices, corners, heatmaps, gridStride=32, randomScale=2), lambda: (point_indices, corners, heatmaps))\n",
        "        #point_indices, corners, heatmaps = augmentWarping(point_indices, corners, heatmaps, gridStride=32, randomScale=4)\n",
        "        pass\n",
        "    if 's' in augmentation:\n",
        "        points, point_indices, corners, heatmaps, imageFeatures = augmentScaling(points, point_indices, corners, heatmaps, imageFeatures)\n",
        "        pass\n",
        "    if 'f' in augmentation:\n",
        "        points, point_indices, corners, heatmaps, imageFeatures = augmentFlipping(points, point_indices, corners, heatmaps, imageFeatures)\n",
        "        pass\n",
        "\n",
        "    iconSegmentation = tf.cast(tf.squeeze(heatmaps[0]), tf.int32)\n",
        "    roomSegmentation = tf.cast(tf.squeeze(heatmaps[1]), tf.int32)\n",
        "\n",
        "    roomSegmentation = tf.minimum(roomSegmentation, NUM_ROOMS - 1)\n",
        "\n",
        "    # point_indices_stack = getCoarseIndicesMaps(point_indices, WIDTH, HEIGHT, 0)\n",
        "\n",
        "    corners = tf.reshape(tf.concat([corners, tf.zeros((MAX_NUM_CORNERS - tf.shape(corners)[0], 3), dtype=tf.int32)], axis=0), (MAX_NUM_CORNERS, 3))\n",
        "    if convertCorners:\n",
        "        cornerSegmentation = tf.stack([tf.sparse_to_dense(tf.stack([corners[:, 1], corners[:, 0]], axis=1), (HEIGHT, WIDTH), corners[:, 2], validate_indices=False)], axis=0)\n",
        "        cornerHeatmaps = tf.one_hot(cornerSegmentation, depth=NUM_CORNERS + 1, axis=-1)[:, :, :, 1:]\n",
        "        #kernel_size = kernelSize\n",
        "        #neighbor_kernel_array = disk(kernel_size)\n",
        "        #neighbor_kernel = tf.constant(neighbor_kernel_array.reshape(-1), shape=neighbor_kernel_array.shape, dtype=tf.float32)\n",
        "        #neighbor_kernel = tf.reshape(neighbor_kernel, [kernel_size, kernel_size, 1, 1])\n",
        "        #cornerHeatmaps = tf.nn.depthwise_conv2d(cornerHeatmaps, tf.tile(neighbor_kernel, [1, 1, NUM_CORNERS, 1]), strides=[1, 1, 1, 1], padding='SAME')\n",
        "        corners = tf.cast(cornerHeatmaps > 0.5, tf.float32)\n",
        "\n",
        "    # cornerSegmentation = tf.sparse_to_dense(tf.stack([corners[:, 1], corners[:, 0]], axis=1), (HEIGHT, WIDTH), corners[:, 2], validate_indices=False)\n",
        "    # cornerHeatmaps = tf.one_hot(cornerSegmentation, depth=NUM_CORNERS, axis=-1)\n",
        "    # kernel = tf.tile(tf.expand_dims(tf.constant(disk(11)), -1), [1, 1, NUM_CORNERS])\n",
        "    # cornerHeatmaps = tf.nn.dilation2d(tf.expand_dims(cornerHeatmaps, 0), kernel, [1, 1, 1, 1], [1, 1, 1, 1], 'SAME')[0]\n",
        "\n",
        "    imagePath = features['image_path']\n",
        "\n",
        "    points = tf.concat([points, tf.ones((NUM_POINTS, 1))], axis=1)\n",
        "\n",
        "    if readImageFeatures:\n",
        "        input_dict = {'points': points, 'point_indices': point_indices, 'image_features': imageFeatures, 'image_path': imagePath, 'flags': flags}\n",
        "    else:\n",
        "        input_dict = {'points': points, 'point_indices': point_indices, 'image_path': imagePath, 'flags': flags}\n",
        "        pass\n",
        "    gt_dict = {'corner': corners, 'icon': iconSegmentation, 'room': roomSegmentation, 'num_corners': numCorners}\n",
        "    return input_dict, gt_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3-mOb8w8DKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_dataset = tf.data.TFRecordDataset(filenames[0])\n",
        "parsed_dataset = raw_dataset.map(parse_fn)\n",
        "def saveImages(typed):\n",
        "    num=1 \n",
        "    for i in parsed_dataset:\n",
        "        cv2.imwrite(\"./data/train/GTv3/{}s_mask/{}_mask_{}.bmp\".format(typed,typed,num)\n",
        "                    ,i[1][typed].numpy())#(.format(typed,typed,num)) \n",
        "#         break\n",
        "        num+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHeGWrNfFGlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveImages(\"room\") \n",
        "saveImages(\"icon\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAWZkr_5Fanm",
        "colab_type": "text"
      },
      "source": [
        "## Extractiong boundary and wall masks\n",
        "After extracting the dataset, run the cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIEbmPxQFfQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveNonSegmentedImages(typed):\n",
        "    if typed=='room':\n",
        "        for i in range(1,136):\n",
        "            image=np.array(Image.open(\"./data/train/GTv3/{}s_mask/{}_mask_{}.bmp\".format(typed,typed,i)))\n",
        "            newImage=image.copy()\n",
        "            newImage[image==0]=255\n",
        "            newImage[image!=15]=255\n",
        "            newImage[image==15]=0\n",
        "            cv2.imwrite(\"./data/train/NonSegmentv1/{}s/{}_{}.bmp\".format(typed,typed,i),newImage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMKXpjuzst7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveNonSegmentedImages(\"room\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrnwvmtssxmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def saveBoundary():\n",
        "    for ind in range(1,136):\n",
        "        origImage=np.array(Image.open(\"./data/train/GTv3/rooms_mask/room_mask_{}.bmp\".format(ind)))\n",
        "        floorImage=np.ones((256,256))\n",
        "        for i in range(2,254):\n",
        "            for j in range(2,254):\n",
        "                flag=0\n",
        "                temp=origImage[i-2:i+3,j-2:j+3]\n",
        "                tempCount=np.unique(temp,return_counts=1)\n",
        "                if(i-3>=0 and origImage[i-3][j]==0) or (i+3<=255 and origImage[i+3][j]==0) or (j-3>=0 \n",
        "                    and origImage[i][j-3]==0) or (j+3<=255 and origImage[i][j+3]==0):\n",
        "                    flag=1\n",
        "                if(flag==1 and temp[0][0]==15 and tempCount[1][0]==25):\n",
        "                    floorImage[i-2:i+3,j-2:j+3]=0\n",
        "        floorImage[floorImage==1]=255\n",
        "        cv2.imwrite(\"./data/train/NonSegmentv1/onlyBoundary/boundary_{}.bmp\".format(ind),floorImage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PhZ_bg5s2nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saveBoundary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}